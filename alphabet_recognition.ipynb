{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72639853",
   "metadata": {},
   "source": [
    "# Necessary installs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607a98b3",
   "metadata": {},
   "source": [
    "Considering you are running this notebook inside an anaconda environment (env), you alaready have python and pip install along with many libraries for python. In this step, we will update them to the latest version for this env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8beba770",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# %%capture used to hide output of a cell in jupyter notebook, comment this statement if encountering any import problems.\n",
    "\n",
    "# using \"pip\" package manager to install/update packages.\n",
    "!pip install keras\n",
    "!pip install scipy\n",
    "!pip install tensorflow\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install sklearn\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67f161b-eeb0-424a-8134-8ff889a92a64",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f53e90-8b21-4ae0-af88-1c55c2e30ed6",
   "metadata": {},
   "source": [
    "All the necessary imports to make our notebook functional are mentioned here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4baaf276-599f-4eb7-8f03-2a764ead8521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import scipy\n",
    "import pandas\n",
    "import sklearn\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e64ae0",
   "metadata": {},
   "source": [
    "# Importing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88ccbde",
   "metadata": {},
   "source": [
    "Using pandas to read the dataset we have stored in csv format (download link in end cell with resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "731d3504",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pandas.read_csv(r'./Dataset/A_Z Handwritten Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4361e0",
   "metadata": {},
   "source": [
    "Visualizing few values of dataset using pandas **.head()** method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89e3b676",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "      <th>...</th>\n",
       "      <th>0.639</th>\n",
       "      <th>0.640</th>\n",
       "      <th>0.641</th>\n",
       "      <th>0.642</th>\n",
       "      <th>0.643</th>\n",
       "      <th>0.644</th>\n",
       "      <th>0.645</th>\n",
       "      <th>0.646</th>\n",
       "      <th>0.647</th>\n",
       "      <th>0.648</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  ...  0.639  0.640  0.641  \\\n",
       "0  0    0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "1  0    0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "2  0    0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "3  0    0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "4  0    0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "5  0    0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "6  0    0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "7  0    0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "8  0    0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "9  0    0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
       "\n",
       "   0.642  0.643  0.644  0.645  0.646  0.647  0.648  \n",
       "0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0  \n",
       "5      0      0      0      0      0      0      0  \n",
       "6      0      0      0      0      0      0      0  \n",
       "7      0      0      0      0      0      0      0  \n",
       "8      0      0      0      0      0      0      0  \n",
       "9      0      0      0      0      0      0      0  \n",
       "\n",
       "[10 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10) #Specifying that we need to read only top (head) 10 values of the given dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1699f7da",
   "metadata": {},
   "source": [
    "**Note:** Later in the notebook, we would have to scale the data, as scaling the data increases accuracy in neural networks. Scaling is a technique used in ML to improve the accuracy of models, in out case, neaural networks. Scaling is nothing but manipulating the values of dataset such that all the input values are in range between 0 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a52359",
   "metadata": {},
   "source": [
    "How scaling helps? [Link](https://analyticsindiamag.com/why-data-scaling-is-important-in-machine-learning-how-to-effectively-do-it/#:~:text=scaling%20of%20the%20data%20makes%20it%20easy%20for%20a%20model%20to%20learn%20and%20understand%20the%20problem.%20In%20the%20case%20of%20neural%20networks%2C%20an%20independent%20variable%20with%20a%20spread%20of%20values%20may%20result%20in%20a%20large%20loss%20in%20training%20and%20testing%20and%20cause%20the%20learning%20process%20to%20be%20unstable.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b9fe1a",
   "metadata": {},
   "source": [
    "### Shuffling dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7928a35d",
   "metadata": {},
   "source": [
    "To break continiuity of data, we have to shuffle the dataset so that out model can train on all possible inputs. We will shuffle using the **numpy.random.shuffle(x)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54e8da1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22b9c37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "      <th>...</th>\n",
       "      <th>0.639</th>\n",
       "      <th>0.640</th>\n",
       "      <th>0.641</th>\n",
       "      <th>0.642</th>\n",
       "      <th>0.643</th>\n",
       "      <th>0.644</th>\n",
       "      <th>0.645</th>\n",
       "      <th>0.646</th>\n",
       "      <th>0.647</th>\n",
       "      <th>0.648</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94286</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185879</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196424</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104604</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29642</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86006</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69976</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185379</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58835</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21979</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  ...  0.639  0.640  \\\n",
       "94286   10    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "185879  14    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "196424  14    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "104604  11    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "29642    2    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "86006    9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "69976    6    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "185379  14    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "58835    4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "21979    1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "        0.641  0.642  0.643  0.644  0.645  0.646  0.647  0.648  \n",
       "94286       0      0      0      0      0      0      0      0  \n",
       "185879      0      0      0      0      0      0      0      0  \n",
       "196424      0      0      0      0      0      0      0      0  \n",
       "104604      0      0      0      0      0      0      0      0  \n",
       "29642       0      0      0      0      0      0      0      0  \n",
       "86006       0      0      0      0      0      0      0      0  \n",
       "69976       0      0      0      0      0      0      0      0  \n",
       "185379      0      0      0      0      0      0      0      0  \n",
       "58835       0      0      0      0      0      0      0      0  \n",
       "21979       0      0      0      0      0      0      0      0  \n",
       "\n",
       "[10 rows x 785 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ba3f75",
   "metadata": {},
   "source": [
    "### Dividing the dataset in X & Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c35a44",
   "metadata": {},
   "source": [
    "As typically in mathematics, we assign images to X variable, and the corresponding value of vayiable to variable Y, because this data has correct values, it can be used for supervised learning. The real values of images are mentioned in column '0', hence we will remove it from variable X, and substitute in variable Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbee261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop('0', axis = 1)\n",
    "# The drop() function is used to drop specified labels from rows or columns.\n",
    "# Axis: Whether to drop labels from the index (0 - ‘index’) or columns (1 - ‘columns’).\n",
    "# so dataset.drop specifies to drop 0th index column wise.\n",
    "\n",
    "Y = dataset['0']\n",
    "# Assigning lable '0' to values variable Y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35c6921",
   "metadata": {},
   "source": [
    "### Splitting data into test and train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bc69d3",
   "metadata": {},
   "source": [
    "In ML, we split data in ratios to first train our model/network, and then test the model with different set of data to check on how much accurate our model is to predict classes. This can only be done in supervised learning as we have the values to our inputs only in supervised dataset. The ratio is generally kept 80-20, 80% for train and 20% for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c48506d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Assigning first 80% of values of X to X_train, and rest 20% to X_test\n",
    "X_train = X[:int((X.shape[0]/100)*80)]\n",
    "X_test = X[int((X.shape[0]/100)*80)+1:]\n",
    "\n",
    "# Similarly assigning first 80% of values of Y to Y_train, and rest 20% to Y_test\n",
    "Y_train = Y[:int((Y.shape[0]/100)*80)]\n",
    "Y_test = Y[int((Y.shape[0]/100)*80)+1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc652d8",
   "metadata": {},
   "source": [
    "### Reshaping the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a7f79b",
   "metadata": {},
   "source": [
    "The data provided to us in the csv file is linear data, because it much more compressible. We have to convert the 784 columns back into form of 28x28 so that we can actually see what the image looks like.\n",
    "\n",
    "We will use **numpy.reshape()** to reshape the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44641a69",
   "metadata": {},
   "source": [
    "**Initially, shape of X_train & X_test respectively:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d943113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (297960, 784), X_test shape: (74489, 784)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train shape: {X_train.shape}, X_test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e230637",
   "metadata": {},
   "source": [
    "**Reshaping:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57c8f057",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reshaped = np.reshape(X_train.values, (X_train.shape[0], 28, 28))\n",
    "X_test_reshaped = np.reshape(X_test.values, (X_test.shape[0], 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559da429",
   "metadata": {},
   "source": [
    "**Shape of X_train, & X_test after reshaping:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c52fd69c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (297960, 28, 28), X_test shape: (74489, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train shape: {X_train_reshaped.shape}, X_test shape: {X_test_reshaped.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ba7332",
   "metadata": {},
   "source": [
    "We have reshaped the columns of the test data to be 28x28 from 784 which can be seen in above outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d98207b",
   "metadata": {},
   "source": [
    "# Visualizing data from out dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6f7f91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# %matplotlib is a magic function in IPython (interactive python).\n",
    "# %matplotlib inline sets the backend of matplotlib to the 'inline' backend.\n",
    "# When using the 'inline' backend, the matplotlib graphs will be included in the notebook, next to the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff42d1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 14 14 ... 19 14 18]\n"
     ]
    }
   ],
   "source": [
    "# Making a corresponding numpy array of Y_train to visualize the array\n",
    "Y_train_np = np.array(Y_train)\n",
    "print(Y_train_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "575e21f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Matplotlib tutorial link in description\n",
    "plt.imshow(X_train_reshaped[0])\n",
    "## Set plot title, A ASCII value start from 65.\n",
    "plt.title(f'Corresponding value for input: {chr(Y_train_np[0]+65)}')\n",
    "## Turn of the axes from the plot\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42e396f",
   "metadata": {},
   "source": [
    "### Creating word dictionary for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90439b77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J', 10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T', 20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z'}\n"
     ]
    }
   ],
   "source": [
    "# Creating a dictionary to assign values to all the keys available in 0-25 (26 engligh alphabets)\n",
    "word_dict = dict({})\n",
    "# have to specify it is a dictionary by adding dict, otherwise {} becomes set\n",
    "# Running a for loop from 0 to 25\n",
    "for index in range(0, 25+1, 1):\n",
    "    word_dict.update({index: chr(index+65)})\n",
    "    \n",
    "print(word_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399828e0",
   "metadata": {},
   "source": [
    "# Creating Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac647f4",
   "metadata": {},
   "source": [
    "We use tensorflow libraty to create our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f7deb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tensorflow.keras.models.Sequential([\n",
    "    tensorflow.keras.layers.Flatten(input_shape = (28, 28)),\n",
    "    tensorflow.keras.layers.Dense(26, activation = 'sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cbcdd2",
   "metadata": {},
   "source": [
    "\n",
    "- In the above created model, we specify that out model is sequential which means that layers of our\n",
    " model will be stacked one over the other. [tf->model->Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)\n",
    "- Inside our model, we first specify that out input shape is 28x28, which we want to flatten and use as an input.\n",
    "- In the next line we specify that out first layer is Dense. Which is just a regular densely connected neural network.\n",
    " Every node if connected to every other node in previous and next layer.\n",
    " [tf->layers->Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)\n",
    "- Inside our dense layer, the first value is the number of output nodes we want to have, then the activation function is\n",
    " specified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cbb414",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55373efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 26)                20410     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,410\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdc70e3",
   "metadata": {},
   "source": [
    "**model.summary()** gives us a summary of the model we have just created, which shows us that we have 2 layers, and the output shape of each layer is depicted. The formulae to calculate trainable parameters for neaural networks in our case (with 0 hidden layers) will be **(i*o)+i** as given [here](https://towardsdatascience.com/number-of-parameters-in-a-feed-forward-neural-network-4e4e33a53655#:~:text=h3%2B%20o-,T,-hus%2C%20the%20formula) where i is the number of input layers, & o is the number of output layers. Placing values into the formulae girves us (784*26)+784 = 20410."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b786bf2f",
   "metadata": {},
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8364791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy',],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9325f3d",
   "metadata": {},
   "source": [
    "- To compile a model in deep learning means to simply make the model transpose to highly efficient matrix, such that machine can train on that model.\n",
    "- The optimizer we used is [Adams optimizer](https://arxiv.org/abs/1412.6980), which is generally used for stochastic gradient decent deep learning algorithms ([Stochastic in plain terms means random](https://towardsdatascience.com/stochastic-gradient-descent-clearly-explained-53d239905d31#:~:text=%E2%80%9CStochastic%E2%80%9D%2C%20in%20plain%20terms%20means%20%E2%80%9Crandom%E2%80%9D.)).\n",
    "- The loss function used is [SparseCategoricalCrossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy) which is meant for model with multiple classes (we have 26) and where classes are rpresented as integers (ours have 0 to 25).\n",
    "- The 3rd parameter \"metrics\" let's us choose the factors we want to judge our model's performance on. For now, accuracy of the model is only factor we care about."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ec85ac",
   "metadata": {},
   "source": [
    "# Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e041b5",
   "metadata": {},
   "source": [
    "- Matplotlib image tutorial: [Matplotlib Tutorial](https://matplotlib.org/stable/tutorials/introductory/images.html)\n",
    "- Dataset link: [Kaggle](https://www.kaggle.com/datasets/sachinpatel21/az-handwritten-alphabets-in-csv-format?resource=download)\n",
    "- Dataset download link: [link](https://storage.googleapis.com/kaggle-data-sets/9726/17999/compressed/A_Z%20Handwritten%20Data.csv.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20221216%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20221216T120321Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=aa3278d2a93e19eec7339c39a706371d6356066c7c04e30e9e470e43d3ce694cb00e100ce6ad4f219f4277dfbc58e19645d4a899b568b407685e9e786b2369e0e47133c84c6173445e96ae2d768413f54a6e5460dae72ab7001a504e012b9775a699bcda5d0fb91f22fcc1edd5386f5b8b83f216c225aaa6e53a367eab63cd956797f648e85f0e6ce0577d2b5487402ec12f3c544af4d8b1691343ccc69229cf81f5f981a7830fdefdd8c0d2b5731ce20c49d193b9f19eae6d7090ba5013b5f4616ddfbd4679efbddd2d217c8ecb872fa094d4459a636bbcd6226b3ec291b9e1b64da18905d3e11cd7c0c8ff599e8b827f195d600ec858215ca582af31b114de)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
