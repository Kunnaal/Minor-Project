{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72639853",
   "metadata": {},
   "source": [
    "# Necessary installs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607a98b3",
   "metadata": {},
   "source": [
    "Considering you are running this notebook inside an anaconda environment (env), you already have python and pip installed along with many libraries for python. In this step, we will update them to the latest version for this env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8beba770",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# %%capture used to hide output of a cell in jupyter notebook, comment this statement if encountering any import problems.\n",
    "\n",
    "# using \"pip\" package manager to install/update packages.\n",
    "!pip install keras\n",
    "!pip install scipy\n",
    "!pip install tensorflow\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install sklearn\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67f161b-eeb0-424a-8134-8ff889a92a64",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f53e90-8b21-4ae0-af88-1c55c2e30ed6",
   "metadata": {},
   "source": [
    "All the necessary imports to make our notebook functional are mentioned here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4baaf276-599f-4eb7-8f03-2a764ead8521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import scipy\n",
    "import random\n",
    "import pandas\n",
    "import sklearn\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e64ae0",
   "metadata": {},
   "source": [
    "# Importing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88ccbde",
   "metadata": {},
   "source": [
    "Using pandas to read the dataset we have stored in csv format (download link in end cell with resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "731d3504",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pandas.read_csv(r'./Dataset/A_Z Handwritten Data.csv').astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4361e0",
   "metadata": {},
   "source": [
    "Visualizing few values of dataset using pandas **.head()** method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89e3b676",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "      <th>...</th>\n",
       "      <th>0.639</th>\n",
       "      <th>0.640</th>\n",
       "      <th>0.641</th>\n",
       "      <th>0.642</th>\n",
       "      <th>0.643</th>\n",
       "      <th>0.644</th>\n",
       "      <th>0.645</th>\n",
       "      <th>0.646</th>\n",
       "      <th>0.647</th>\n",
       "      <th>0.648</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  ...  0.639  0.640  0.641  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "6  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "8  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "9  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0    0.0   \n",
       "\n",
       "   0.642  0.643  0.644  0.645  0.646  0.647  0.648  \n",
       "0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "5    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "6    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "7    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "8    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "9    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[10 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10) #Specifying that we need to read only top (head) 10 values of the given dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1699f7da",
   "metadata": {},
   "source": [
    "**Note:** Later in the notebook, we would have to scale the data, as scaling the data increases accuracy in neural networks. Scaling is a technique used in ML to improve the accuracy of models, in our case, neaural networks. Scaling is nothing but manipulating the values of dataset such that all the input values are in range between 0 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a52359",
   "metadata": {},
   "source": [
    "How scaling helps? [Link](https://analyticsindiamag.com/why-data-scaling-is-important-in-machine-learning-how-to-effectively-do-it/#:~:text=scaling%20of%20the%20data%20makes%20it%20easy%20for%20a%20model%20to%20learn%20and%20understand%20the%20problem.%20In%20the%20case%20of%20neural%20networks%2C%20an%20independent%20variable%20with%20a%20spread%20of%20values%20may%20result%20in%20a%20large%20loss%20in%20training%20and%20testing%20and%20cause%20the%20learning%20process%20to%20be%20unstable.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b9fe1a",
   "metadata": {},
   "source": [
    "### Shuffling dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7928a35d",
   "metadata": {},
   "source": [
    "To break continiuity of data, we have to shuffle the dataset so that our model can train on all possible inputs. We will shuffle using the **numpy.random.shuffle(x)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54e8da1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.sample(frac = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22b9c37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "      <th>...</th>\n",
       "      <th>0.639</th>\n",
       "      <th>0.640</th>\n",
       "      <th>0.641</th>\n",
       "      <th>0.642</th>\n",
       "      <th>0.643</th>\n",
       "      <th>0.644</th>\n",
       "      <th>0.645</th>\n",
       "      <th>0.646</th>\n",
       "      <th>0.647</th>\n",
       "      <th>0.648</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32565</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20265</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79265</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256162</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347128</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206901</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273812</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75724</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275300</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9925</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  ...  0.639  0.640  \\\n",
       "32565    2.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "20265    1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "79265    7.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "256162  18.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "347128  22.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "206901  15.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "273812  18.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "75724    7.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "275300  18.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "9925     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0    0.0   \n",
       "\n",
       "        0.641  0.642  0.643  0.644  0.645  0.646  0.647  0.648  \n",
       "32565     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "20265     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "79265     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "256162    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "347128    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "206901    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "273812    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "75724     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "275300    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "9925      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[10 rows x 785 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ba3f75",
   "metadata": {},
   "source": [
    "### Dividing the dataset in X & Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c35a44",
   "metadata": {},
   "source": [
    "Typically in mathematics, we assign inputs to X variable, and the corresponding value of variable Y. As this data has correct values, it can be used for supervised learning. The real values of images are mentioned in column '0', hence we will remove it from variable X, and substitute in variable Y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbee261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop('0', axis = 1)\n",
    "# The drop() function is used to drop specified labels from rows or columns.\n",
    "# Axis: Whether to drop labels from the index (0 - ‘index’) or columns (1 - ‘columns’).\n",
    "# so dataset.drop specifies to drop 0th index column wise.\n",
    "\n",
    "Y = dataset['0']\n",
    "# Assigning lable '0' to values variable Y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35c6921",
   "metadata": {},
   "source": [
    "### Splitting data into test and train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bc69d3",
   "metadata": {},
   "source": [
    "In ML, we split data in ratios to first train our model/network, and then test the model with different set of data to check on how accurate our model is to predict classes. This can only be done in supervised learning as we have the values to our inputs only in supervised dataset. The ratio is generally kept 80-20, 80% for train and 20% for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c48506d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Assigning first 80% of values of X to X_train, and rest 20% to X_test\n",
    "X_train = X[:int((X.shape[0]/100)*80)]/255\n",
    "X_test = X[int((X.shape[0]/100)*80)+1:]/255\n",
    "# Also scaling the data by dividing it by 255 as it is in range 0-255\n",
    "\n",
    "# Similarly assigning first 80% of values of Y to Y_train, and rest 20% to Y_test\n",
    "Y_train = Y[:int((Y.shape[0]/100)*80)]\n",
    "Y_test = Y[int((Y.shape[0]/100)*80)+1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc652d8",
   "metadata": {},
   "source": [
    "### Reshaping the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a7f79b",
   "metadata": {},
   "source": [
    "The data provided to us in the csv file is linear data, because it much more compressible. We have to convert the 784 columns back into form of 28x28 so that we can actually see what the image looks like.\n",
    "\n",
    "We will use **numpy.reshape()** to reshape the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44641a69",
   "metadata": {},
   "source": [
    "**Initially, shape of X_train & X_test respectively:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d943113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (297960, 784), X_test shape: (74489, 784)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train shape: {X_train.shape}, X_test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e230637",
   "metadata": {},
   "source": [
    "**Reshaping:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57c8f057",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reshaped = np.reshape(X_train.values, (X_train.shape[0], 28, 28))\n",
    "X_test_reshaped = np.reshape(X_test.values, (X_test.shape[0], 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559da429",
   "metadata": {},
   "source": [
    "**Shape of X_train, & X_test after reshaping:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c52fd69c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (297960, 28, 28), X_test shape: (74489, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train shape: {X_train_reshaped.shape}, X_test shape: {X_test_reshaped.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ba7332",
   "metadata": {},
   "source": [
    "We have reshaped the columns of the test data to be 28x28 from 784 which can be seen in above output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d98207b",
   "metadata": {},
   "source": [
    "# Visualizing data from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6f7f91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# %matplotlib is a magic function in IPython (interactive python).\n",
    "# %matplotlib inline sets the backend of matplotlib to the 'inline' backend.\n",
    "# When using the 'inline' backend, the matplotlib graphs will be included in the notebook, next to the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff42d1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  1.  7. ... 17. 12. 13.]\n"
     ]
    }
   ],
   "source": [
    "# Making a corresponding numpy array of Y_train to visualize the array\n",
    "Y_train_np = np.array(Y_train)\n",
    "print(Y_train_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "575e21f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Matplotlib tutorial link in description\n",
    "plt.imshow(X_train_reshaped[0])\n",
    "## Set plot title, 'A' ASCII value start from 65.\n",
    "plt.title(f'Corresponding value for input: {chr(int(Y_train_np[0])+65)}')\n",
    "## Turn of the axes from the plot\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e137e6e",
   "metadata": {},
   "source": [
    "### Creating word dictionary for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90439b77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J', 10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T', 20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z'}\n"
     ]
    }
   ],
   "source": [
    "# Creating a dictionary to assign values to all the keys available in 0-25 (26 engligh alphabets)\n",
    "word_dict = dict({})\n",
    "# have to specify it is a dictionary by adding dict, otherwise {} becomes set\n",
    "# Running a for loop from 0 to 25\n",
    "for index in range(0, 25+1, 1):\n",
    "    word_dict.update({index: chr(index+65)})\n",
    "    \n",
    "print(word_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a0b924",
   "metadata": {},
   "source": [
    "# Creating Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca2ff81",
   "metadata": {},
   "source": [
    "We use tensorflow library to create our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f7deb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tensorflow.keras.models.Sequential([\n",
    "    tensorflow.keras.layers.Flatten(input_shape = (28, 28)),\n",
    "    tensorflow.keras.layers.Dense(26, activation = 'sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568d41a1",
   "metadata": {},
   "source": [
    "\n",
    "- In the above created model, we specify that our model is sequential which means that layers of our\n",
    " model will be stacked one over the other. [tf->model->Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential)\n",
    "- Inside our model, we first specify that our input shape is 28x28, which we want to flatten and use as an input.\n",
    "- In the next line we specify that our first layer is Dense. Which is just a regular densely connected neural network.\n",
    " Every node is connected to every other node in previous and next layer.\n",
    " [tf->layers->Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)\n",
    "- Inside our dense layer, the first value is the number of output nodes we want to have, then the activation function is\n",
    " specified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f0e26c",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b36bab94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 26)                20410     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,410\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c181b0b7",
   "metadata": {},
   "source": [
    "**model.summary()** gives us a summary of the model we have just created, which shows us that we have 2 layers, and the output shape of each layer is depicted. The formulae to calculate trainable parameters for neaural networks in our case (with 0 hidden layers) will be **(i*o)+i** as given [here](https://towardsdatascience.com/number-of-parameters-in-a-feed-forward-neural-network-4e4e33a53655#:~:text=h3%2B%20o-,T,-hus%2C%20the%20formula) where i is the number of input layers, & o is the number of output layers. Placing values into the formulae girves us (784*26)+784 = 20410."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa78807",
   "metadata": {},
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56c7f89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy',],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b96bf0c",
   "metadata": {},
   "source": [
    "- To compile a model in deep learning means to simply make the model transpose to highly efficient matrix, such that machine can train on that model.\n",
    "- The optimizer we used is [Adams optimizer](https://arxiv.org/abs/1412.6980), which is generally used for stochastic gradient decent deep learning algorithms ([Stochastic in plain terms means random](https://towardsdatascience.com/stochastic-gradient-descent-clearly-explained-53d239905d31#:~:text=%E2%80%9CStochastic%E2%80%9D%2C%20in%20plain%20terms%20means%20%E2%80%9Crandom%E2%80%9D.)).\n",
    "- The loss function used is [SparseCategoricalCrossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy) which is meant for model with multiple classes (we have 26) and where classes are represented as integers (ours have 0 to 25).\n",
    "- The 3rd parameter \"metrics\" let's us choose the factors we want to judge our model's performance on. For now, accuracy of the model is only factor we care about."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcb1f51",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06c4fe4",
   "metadata": {},
   "source": [
    "We will train the model here using the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7061db00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "9312/9312 [==============================] - 34s 2ms/step - loss: 0.5802 - accuracy: 0.8491\n",
      "Epoch 2/3\n",
      "9312/9312 [==============================] - 23s 2ms/step - loss: 0.4863 - accuracy: 0.8749\n",
      "Epoch 3/3\n",
      "9312/9312 [==============================] - 23s 3ms/step - loss: 0.4763 - accuracy: 0.8779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c733b63c70>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_reshaped, Y_train, epochs = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e304527",
   "metadata": {},
   "source": [
    "- In the above statement, [model.fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) trains our model for a fixed number of epochs and uses the X & Y training data. In our case, we have set the epochs to 3.\n",
    "- Guesseing the number of epochs is a difficult task as it might result in the model being [Overfit/Underfit](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit). Underfit means that we did not provide enough epochs to our model to learn from the train data and it won't perform well. Overfit means our model has learned too much from the data we have provided and will NOT perform well for unseen data (alien to it)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c3ea68",
   "metadata": {},
   "source": [
    "**Note:** As we can see in the above cell, the accuracy of our model is just **87.79%**, the accuracy has definitely increased with each epoch but not much, that is because we don't have any hidden layers for our model to implement on. So upgrades needed for our models will include adding a hidden layer also."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c3108d",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb9174a",
   "metadata": {},
   "source": [
    "Here we will use the [model.evaluate()](https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate) function to evaluate the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0627cf80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2328/2328 [==============================] - 7s 2ms/step - loss: 0.4787 - accuracy: 0.8796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.47867491841316223, 0.8795526623725891]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_reshaped, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84761529",
   "metadata": {},
   "source": [
    "As in above output we can see that the test results are very much close to the training data, hence our model is relatively trained well for the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7977269b",
   "metadata": {},
   "source": [
    "# Predicting values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3848913b",
   "metadata": {},
   "source": [
    "Here we will use [model.predict()](https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict) function to get the output of a prediction and then visualize and see if the predictions were right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1399a07e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAFCklEQVR4nO3doW+USRyA4a/NKcTZSzCEFHMoHCWX4AgaQXDVWAx/xBlUE7A4gkATHIRQHOowEIIhwSKQ7Clcdz5Iu9132+eRO112s+TNJPvLzG4tFosJ6Nle9xsADidOiBInRIkTosQJUX+MFm9s3/ZVLqzYix9Ptw573M4JUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IGv4EID3fb10drl+8/364/vjCy+H63ufrS9e+Xvs2fC7Hy84JUeKEKHFClDghSpwQJU6IEidEmXPGzM0xX+0/Wunrj+age2+Wz0CnyRz0uNk5IUqcECVOiBInRIkTosQJUeKEKHPONfjwYHfp2sc7D0/wnfyeubOgOw/uHunfv3Tv4EjPP23snBAlTogSJ0SJE6LECVHihKitxWKxdPHG9u3li2fYaBQyTe1xSNnN81fW/RbW4sWPp1uHPW7nhChxQpQ4IUqcECVOiBInRIkTohwZO8Rfb/4crj+/YI65CqP58Vk8TmbnhChxQpQ4IUqcECVOiBInRIkTok7tnHP0U3oX778fPnfuCsij2vu8/Kf0Xh9cHj73/MvxEdtzz94O19f9E4P8OjsnRIkTosQJUeKEKHFClDghSpwQdWrnnKNZ5jrnmNM0TV+vfVu6dmla7bnFL9cPvSKVIDsnRIkTosQJUeKEKHFClDghSpwQtbFzzrlziY8vrO5c4s6Tu8P1s3jH6q/wuf0eOydEiROixAlR4oQocUKUOCFqY0cpq7zCce7Il6/8OQl2TogSJ0SJE6LECVHihChxQpQ4ISo75/zwYHfmL96t7LVHV1duurkZ7d7u8hnv3JWijoQdLzsnRIkTosQJUeKEKHFClDghSpwQlZ1z/rP737rfwpk0mvHenK4Mn7vqny88a+ycECVOiBInRIkTosQJUeKEKHFCVHbOOXd28Cjm7qWdptN7npPNYeeEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0Rlj4yt0txxtLkrIOEk2DkhSpwQJU6IEidEiROixAlR4oSo7Jxz7vrKVV6d+f3W1eH6uWdvV/ba8JOdE6LECVHihChxQpQ4IUqcECVOiMrOOT/9+/f4D/ZXN+d8tf9ouH7z2ZWVvTb8ZOeEKHFClDghSpwQJU6IEidEiROisnPO2TOT+yfzPg7z/Mu74frcWdTXB5eXrp1/uRg+d+5z+fBgd7he9vHOw6Vrc5/p12vfjvvtrJ2dE6LECVHihChxQpQ4IUqcELW1WCz/6v7G9u3x9/prNHd95cX775eurfJaTdZj58nd4fqlewcn9E5+34sfT7cOe9zOCVHihChxQpQ4IUqcECVOiBInRGWPjM2ZOzr1aVo+B925vvzI1jSNjy7RNPd/tjNt3hzUzglR4oQocUKUOCFKnBAlTogSJ0Rt7HnOdTrq9ZObOkedOzO5Skf9zMpXazrPCRtGnBAlTogSJ0SJE6LECVHihChzTlgzc07YMOKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IGv4EILA+dk6IEidEiROixAlR4oQocULU//sBugB5cDOnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Displaying the random character\n",
    "plt.imshow((X_train_reshaped[:1])[0])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6933d275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 146ms/step\n",
      "[3.9601677e-05 2.0545501e-04 9.9979317e-01 3.5719524e-06 1.3141927e-01\n",
      " 3.5376793e-20 5.8238599e-03 5.5118153e-06 2.5369479e-11 2.0674885e-04\n",
      " 4.0287114e-06 2.7524848e-05 1.4071243e-07 4.0396959e-08 6.7567714e-02\n",
      " 1.2169726e-13 6.0071781e-02 3.9486121e-04 3.9650456e-04 1.8611532e-12\n",
      " 2.4446763e-02 1.0981937e-10 3.4369878e-09 9.9894641e-11 7.6875189e-08\n",
      " 9.9629833e-05]\n"
     ]
    }
   ],
   "source": [
    "# Predicting the value for the choosen random character from dataset\n",
    "prediction = model.predict((X_train_reshaped[:1]))\n",
    "\n",
    "print(prediction[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5749849",
   "metadata": {},
   "source": [
    "Now we have to look up which class got the max score amongst the availabe 26. We will find max element using **np.argmax()** function, and then use **word_dict** to specify that index is which alphabet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a28cdfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is C\n"
     ]
    }
   ],
   "source": [
    "print(f'Prediction is {word_dict[np.argmax(prediction[0])]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da4291f",
   "metadata": {},
   "source": [
    "Our prediction turned out to be C by the model as was seen in the choosen image. Hence out model is working correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ec85ac",
   "metadata": {},
   "source": [
    "# Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e041b5",
   "metadata": {},
   "source": [
    "- Matplotlib image tutorial: [Matplotlib Tutorial](https://matplotlib.org/stable/tutorials/introductory/images.html)\n",
    "- Dataset link: [Kaggle](https://www.kaggle.com/datasets/sachinpatel21/az-handwritten-alphabets-in-csv-format?resource=download)\n",
    "- Dataset download link: [link](https://storage.googleapis.com/kaggle-data-sets/9726/17999/compressed/A_Z%20Handwritten%20Data.csv.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20221216%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20221216T120321Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=aa3278d2a93e19eec7339c39a706371d6356066c7c04e30e9e470e43d3ce694cb00e100ce6ad4f219f4277dfbc58e19645d4a899b568b407685e9e786b2369e0e47133c84c6173445e96ae2d768413f54a6e5460dae72ab7001a504e012b9775a699bcda5d0fb91f22fcc1edd5386f5b8b83f216c225aaa6e53a367eab63cd956797f648e85f0e6ce0577d2b5487402ec12f3c544af4d8b1691343ccc69229cf81f5f981a7830fdefdd8c0d2b5731ce20c49d193b9f19eae6d7090ba5013b5f4616ddfbd4679efbddd2d217c8ecb872fa094d4459a636bbcd6226b3ec291b9e1b64da18905d3e11cd7c0c8ff599e8b827f195d600ec858215ca582af31b114de)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
